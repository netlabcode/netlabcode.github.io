<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Artificial Intelligence | Cyber-Phsysical Intelligence</title><link>https://netlabcode.github.io/tag/artificial-intelligence/</link><atom:link href="https://netlabcode.github.io/tag/artificial-intelligence/index.xml" rel="self" type="application/rss+xml"/><description>Artificial Intelligence</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 11 Aug 2025 00:00:00 +0000</lastBuildDate><image><url>https://netlabcode.github.io/images/logo.svg</url><title>Artificial Intelligence</title><link>https://netlabcode.github.io/tag/artificial-intelligence/</link></image><item><title>AI for Sport</title><link>https://netlabcode.github.io/artificial-intelligence/ai4sport/</link><pubDate>Mon, 11 Aug 2025 00:00:00 +0000</pubDate><guid>https://netlabcode.github.io/artificial-intelligence/ai4sport/</guid><description>&lt;h3 id="artificial-intelligence-for-sport-application">Artificial Intelligence for Sport Application&lt;/h3>
&lt;p>Advances in artificial intelligence present new opportunities for enhancing sports performance analysis, injury prevention, and strategic decision-making. This research proposes the development of an AI-powered sports analytics framework leveraging the PySport library for data acquisition, processing, and model integration. The system will apply machine learning techniques to extract actionable insights from player statistics, game events, and performance metrics. Predictive models will be designed for talent scouting, match outcome forecasting, and personalized training recommendations. By combining AI-driven analytics with the flexible data handling capabilities of PySport, the project aims to deliver a versatile and scalable solution that supports coaches, analysts, and athletes in data-informed decision-making.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/CWnlGBVaRpQ" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;figure >
&lt;a data-fancybox="" href="https://netlabcode.github.io/artificial-intelligence/ai4sport/shield_hu419380dd6ff4e0658cd2536e184f1ca5_680159_2000x2000_fit_lanczos_2.png" >
&lt;img data-src="https://netlabcode.github.io/artificial-intelligence/ai4sport/shield_hu419380dd6ff4e0658cd2536e184f1ca5_680159_2000x2000_fit_lanczos_2.png" class="lazyload" alt="" width="25%" height="980">
&lt;/a>
&lt;/figure></description></item><item><title>MCP</title><link>https://netlabcode.github.io/miscellaneous/mcp/</link><pubDate>Mon, 11 Aug 2025 00:00:00 +0000</pubDate><guid>https://netlabcode.github.io/miscellaneous/mcp/</guid><description>&lt;h3 id="model-context-protocol-mcp">Model Context Protocol (MCP)&lt;/h3>
&lt;p>The Model Context Protocol (MCP) is an open-source, vendor-agnostic framework introduced by Anthropic in November 2024 that standardizes how large language models (LLMs) integrate with external tools, data sources, and services. Acting as a universal interface—often likened to a USB-C port for AI—MCP enables developers to build AI applications without gluing together numerous custom integrations, thereby solving the pervasive “N×M” connector problem. With client–server architecture, rich SDK support across languages, and growing adoption by major AI platforms, MCP is poised to become the backbone of scalable, interoperable AI systems. This research will analyze MCP’s architecture, evaluate its effectiveness in facilitating multi-tool LLM workflows, and explore security and usability limitations to support its evolution as a reliable standard in AI integration.&lt;/p>
&lt;figure id="figure-">
&lt;a data-fancybox="" href="https://netlabcode.github.io/miscellaneous/mcp/shield_hu419380dd6ff4e0658cd2536e184f1ca5_680159_2000x2000_fit_lanczos_2.png" data-caption="">
&lt;img data-src="https://netlabcode.github.io/miscellaneous/mcp/shield_hu419380dd6ff4e0658cd2536e184f1ca5_680159_2000x2000_fit_lanczos_2.png" class="lazyload" alt="" width="980" height="980">
&lt;/a>
&lt;figcaption>
&lt;/figcaption>
&lt;/figure></description></item><item><title>XAI</title><link>https://netlabcode.github.io/artificial-intelligence/xai/</link><pubDate>Mon, 11 Aug 2025 00:00:00 +0000</pubDate><guid>https://netlabcode.github.io/artificial-intelligence/xai/</guid><description>&lt;h3 id="explainable-artificial-intelligence-xai">Explainable Artificial Intelligence (XAI)&lt;/h3>
&lt;p>The growing adoption of artificial intelligence in critical domains such as healthcare, finance, and cybersecurity demands models that are not only accurate but also transparent and trustworthy. This research aims to develop Explainable AI (XAI) methods that provide clear, interpretable insights into model decision-making without sacrificing performance. By combining model-agnostic explanation techniques with inherently interpretable architectures, the proposed approach seeks to enhance user trust, support regulatory compliance, and facilitate human–AI collaboration. The study will evaluate these methods across multiple application domains, assessing their effectiveness in improving transparency, detectability of bias, and actionable decision support.&lt;/p>
&lt;figure >
&lt;a data-fancybox="" href="https://netlabcode.github.io/artificial-intelligence/xai/shield_hu419380dd6ff4e0658cd2536e184f1ca5_680159_2000x2000_fit_lanczos_2.png" >
&lt;img data-src="https://netlabcode.github.io/artificial-intelligence/xai/shield_hu419380dd6ff4e0658cd2536e184f1ca5_680159_2000x2000_fit_lanczos_2.png" class="lazyload" alt="" width="25%" height="980">
&lt;/a>
&lt;/figure></description></item></channel></rss>